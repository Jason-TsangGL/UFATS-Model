{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np,sys,os\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import os as os\n",
    "import nrrd as reader\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage import segmentation\n",
    "from skimage.segmentation import flood, flood_fill\n",
    "from skimage.measure import label\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage import data, io, img_as_ubyte,filters\n",
    "from time import sleep\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, Concatenate\n",
    "def unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    up6 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = Concatenate()([drop4, up6])\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = Concatenate()([conv3, up7])\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = Concatenate()([conv2, up8])\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(32, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = Concatenate()([conv1, up9])\n",
    "    conv9 = Conv2D(32, 3, activation ='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(32, 3, activation='relu', padding='same')(conv9)\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading previously processed DCM and Mask arrays into NumPy arrays.\n",
    "RawDCMArray = np.load(\"RAW-DCM-ARRAY.npy\")\n",
    "NormDCMArray = np.load(\"NORM-DCM-ARRAY.npy\")\n",
    "MSKMaskArray = np.load(\"DCM-SEG-MASK.npy\")\n",
    "FLEMaskArray = np.load(\"DCM-FLE-MASK.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mpredict()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "1608/1608 [==============================] - 635s 394ms/step - loss: 0.1050 - accuracy: 0.9550 - val_loss: 0.0417 - val_accuracy: 0.9840\n",
      "Epoch 2/16\n",
      "1608/1608 [==============================] - 649s 404ms/step - loss: 0.0405 - accuracy: 0.9858 - val_loss: 0.0310 - val_accuracy: 0.9893\n",
      "Epoch 3/16\n",
      "1608/1608 [==============================] - 650s 404ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 0.0243 - val_accuracy: 0.9904\n",
      "Epoch 4/16\n",
      "1608/1608 [==============================] - 656s 408ms/step - loss: 0.0278 - accuracy: 0.9901 - val_loss: 0.0484 - val_accuracy: 0.9850\n",
      "Epoch 5/16\n",
      "1608/1608 [==============================] - 625s 388ms/step - loss: 0.0350 - accuracy: 0.9875 - val_loss: 0.0210 - val_accuracy: 0.9918\n",
      "Epoch 6/16\n",
      "1608/1608 [==============================] - 621s 386ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 0.0378 - val_accuracy: 0.9893\n",
      "Epoch 7/16\n",
      "1608/1608 [==============================] - 628s 391ms/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 0.0213 - val_accuracy: 0.9915\n",
      "Epoch 8/16\n",
      "1608/1608 [==============================] - 638s 397ms/step - loss: 0.0342 - accuracy: 0.9907 - val_loss: 0.0202 - val_accuracy: 0.9920\n",
      "Epoch 9/16\n",
      "1608/1608 [==============================] - 640s 398ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0210 - val_accuracy: 0.9917\n",
      "Epoch 10/16\n",
      "1608/1608 [==============================] - 640s 398ms/step - loss: 0.0220 - accuracy: 0.9919 - val_loss: 0.0184 - val_accuracy: 0.9926\n",
      "Epoch 11/16\n",
      "1608/1608 [==============================] - 641s 399ms/step - loss: 0.0202 - accuracy: 0.9923 - val_loss: 0.0181 - val_accuracy: 0.9927\n",
      "Epoch 12/16\n",
      "1608/1608 [==============================] - 640s 398ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.0185 - val_accuracy: 0.9928\n",
      "Epoch 13/16\n",
      "1608/1608 [==============================] - 640s 398ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.0167 - val_accuracy: 0.9931\n",
      "Epoch 14/16\n",
      "1608/1608 [==============================] - 639s 398ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 0.0180 - val_accuracy: 0.9930\n",
      "Epoch 15/16\n",
      "1608/1608 [==============================] - 640s 398ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.0185 - val_accuracy: 0.9926\n",
      "Epoch 16/16\n",
      "1608/1608 [==============================] - 638s 397ms/step - loss: 0.0178 - accuracy: 0.9928 - val_loss: 0.0193 - val_accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "dicoms = (RawDCMArray - np.min(RawDCMArray)) / (np.max(RawDCMArray) - np.min(RawDCMArray))\n",
    "masks = (FLEMaskArray - np.min(FLEMaskArray)) / (np.max(FLEMaskArray) - np.min(FLEMaskArray))\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(dicoms, masks, test_size=0.2)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "loss = 'binary_crossentropy'\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# Compile your model\n",
    "model = unet(dicoms[0].shape)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train your model using the fit() function\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=16, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelv2 = unet(dicoms[0].shape)\n",
    "modelv2.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])\n",
    "modelv2val = modelv2.fit(x_train,y_train,batch_size=15,epochs=16,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save(\"modelv1.h5\")\n",
    "modelv2.save(\"modelv2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save only model weights\n",
    "model.save_weights(\"modelv1_weights.h5\")\n",
    "modelv2.save_weights(\"modelv2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hw66ln2H3YzQ",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Conv2DBackpropInput_device_/job:localhost/replica:0/task:0/device:CPU:0}} Conv2DCustomBackpropInput: input and out_backprop must have the same batch size. Input batch: 2, outbackprop batch: 0, batch_dim: 0 [Op:Conv2DBackpropInput]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 128\u001b[0m\n\u001b[0;32m    125\u001b[0m layer5_3 \u001b[38;5;241m=\u001b[39m l5_3\u001b[38;5;241m.\u001b[39mfeedforward(layer5_2)\n\u001b[0;32m    127\u001b[0m layer6_Input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([layer5_3,layer5_Input],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m layer6_1 \u001b[38;5;241m=\u001b[39m \u001b[43ml6_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeedforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer6_Input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m layer6_2 \u001b[38;5;241m=\u001b[39m l6_2\u001b[38;5;241m.\u001b[39mfeedforward(layer6_1)\n\u001b[0;32m    130\u001b[0m layer6_3 \u001b[38;5;241m=\u001b[39m l6_3\u001b[38;5;241m.\u001b[39mfeedforward(layer6_2)\n",
      "Cell \u001b[1;32mIn[18], line 38\u001b[0m, in \u001b[0;36mconlayer_right.feedforward\u001b[1;34m(self, input, stride, dilate, output)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m     36\u001b[0m current_shape_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurrent_shape_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurrent_shape_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurrent_shape_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerA \u001b[38;5;241m=\u001b[39m tf_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerA\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Conv2DBackpropInput_device_/job:localhost/replica:0/task:0/device:CPU:0}} Conv2DCustomBackpropInput: input and out_backprop must have the same batch size. Input batch: 2, outbackprop batch: 0, batch_dim: 0 [Op:Conv2DBackpropInput]"
     ]
    }
   ],
   "source": [
    "#Custom UFATS UNET Model 2019\n",
    "\n",
    "np.random.seed(678)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "def tf_relu(x): return tf.nn.relu(x)\n",
    "def d_tf_relu(s): return tf.cast(tf.greater(s,0),dtype=tf.float32)\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def np_sigmoid(x): return 1/(1 + np.exp(-1 *x))\n",
    "\n",
    "# --- hyper ---\n",
    "num_epoch = 100\n",
    "init_lr = 0.0001\n",
    "batch_size = 2\n",
    "\n",
    "# --- make class ---\n",
    "class conlayer_left():\n",
    "    \n",
    "    def __init__(self,ker,in_c,out_c):\n",
    "        self.w = tf.Variable(tf.random.normal([ker,ker,in_c,out_c],stddev=0.05))\n",
    "\n",
    "    def feedforward(self,input,stride=1,dilate=1, output=1):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides = [1,stride,stride,1],padding='SAME')\n",
    "        self.layerA = tf_relu(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "class conlayer_right():\n",
    "    \n",
    "    def __init__(self,ker,in_c,out_c):\n",
    "        self.w = tf.Variable(tf.random.normal([ker,ker,in_c,out_c],stddev=0.05))\n",
    "\n",
    "    def feedforward(self,input,stride=1,dilate=1,output=1):\n",
    "        self.input  = input\n",
    "    \n",
    "        current_shape_size = input.shape\n",
    "\n",
    "        self.layer = tf.nn.conv2d_transpose(input,self.w,\n",
    "        output_shape=[batch_size] + [int(current_shape_size[1]*2),int(current_shape_size[2]*2),int(current_shape_size[3]/2)],strides=[1, stride, stride, 1],padding='SAME')\n",
    "        self.layerA = tf_relu(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_images = dicoms[:,:,:,0]\n",
    "train_labels = masks[:,:,:,0]\n",
    "\n",
    "train_images = (train_images - train_images.min()) / (train_images.max() - train_images.min())\n",
    "train_labels = (train_labels - train_labels.min()) / (train_labels.max() - train_labels.min())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- make layer ---\n",
    "# left\n",
    "l1_1 = conlayer_left(3,1,3)\n",
    "l1_2 = conlayer_left(3,3,3)\n",
    "l1_3 = conlayer_left(3,3,3)\n",
    "\n",
    "l2_1 = conlayer_left(3,3,6)\n",
    "l2_2 = conlayer_left(3,6,6)\n",
    "l2_3 = conlayer_left(3,6,6)\n",
    "\n",
    "l3_1 = conlayer_left(3,6,12)\n",
    "l3_2 = conlayer_left(3,12,12)\n",
    "l3_3 = conlayer_left(3,12,12)\n",
    "\n",
    "l4_1 = conlayer_left(3,12,24)\n",
    "l4_2 = conlayer_left(3,24,24)\n",
    "l4_3 = conlayer_left(3,24,24)\n",
    "\n",
    "l5_1 = conlayer_left(3,24,48)\n",
    "l5_2 = conlayer_left(3,48,48)\n",
    "l5_3 = conlayer_left(3,48,24)\n",
    "\n",
    "# right\n",
    "l6_1 = conlayer_right(3,24,48)\n",
    "l6_2 = conlayer_left(3,24,24)\n",
    "l6_3 = conlayer_left(3,24,12)\n",
    "\n",
    "l7_1 = conlayer_right(3,12,24)\n",
    "l7_2 = conlayer_left(3,12,12)\n",
    "l7_3 = conlayer_left(3,12,6)\n",
    "\n",
    "l8_1 = conlayer_right(3,6,12)\n",
    "l8_2 = conlayer_left(3,6,6)\n",
    "l8_3 = conlayer_left(3,6,3)\n",
    "\n",
    "l9_1 = conlayer_right(3,3,6)\n",
    "l9_2 = conlayer_left(3,3,3)\n",
    "l9_3 = conlayer_left(3,3,3)\n",
    "\n",
    "l10_final = conlayer_left(3,3,1)\n",
    "\n",
    "# ---- make graph ----\n",
    "\n",
    "x = np.empty([0,256,256,1],dtype= np.float32)\n",
    "y = np.empty([0,256,256,1],dtype= np.float32)\n",
    "\n",
    "layer1_1 = l1_1.feedforward(x)\n",
    "layer1_2 = l1_2.feedforward(layer1_1)\n",
    "layer1_3 = l1_3.feedforward(layer1_2)\n",
    "\n",
    "layer2_Input = tf.nn.max_pool(layer1_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer2_1 = l2_1.feedforward(layer2_Input)\n",
    "layer2_2 = l2_2.feedforward(layer2_1)\n",
    "layer2_3 = l2_3.feedforward(layer2_2)\n",
    "\n",
    "layer3_Input = tf.nn.max_pool(layer2_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer3_1 = l3_1.feedforward(layer3_Input)\n",
    "layer3_2 = l3_2.feedforward(layer3_1)\n",
    "layer3_3 = l3_3.feedforward(layer3_2)\n",
    "\n",
    "layer4_Input = tf.nn.max_pool(layer3_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer4_1 = l4_1.feedforward(layer4_Input)\n",
    "layer4_2 = l4_2.feedforward(layer4_1)\n",
    "layer4_3 = l4_3.feedforward(layer4_2)\n",
    "\n",
    "layer5_Input = tf.nn.max_pool(layer4_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer5_1 = l5_1.feedforward(layer5_Input)\n",
    "layer5_2 = l5_2.feedforward(layer5_1)\n",
    "layer5_3 = l5_3.feedforward(layer5_2)\n",
    "\n",
    "layer6_Input = tf.concat([layer5_3,layer5_Input],axis=3)\n",
    "layer6_1 = l6_1.feedforward(layer6_Input)\n",
    "layer6_2 = l6_2.feedforward(layer6_1)\n",
    "layer6_3 = l6_3.feedforward(layer6_2)\n",
    "\n",
    "layer7_Input = tf.concat([layer6_3,layer4_Input],axis=3)\n",
    "layer7_1 = l7_1.feedforward(layer7_Input)\n",
    "layer7_2 = l7_2.feedforward(layer7_1)\n",
    "layer7_3 = l7_3.feedforward(layer7_2)\n",
    "\n",
    "layer8_Input = tf.concat([layer7_3,layer3_Input],axis=3)\n",
    "layer8_1 = l8_1.feedforward(layer8_Input)\n",
    "layer8_2 = l8_2.feedforward(layer8_1)\n",
    "layer8_3 = l8_3.feedforward(layer8_2)\n",
    "\n",
    "layer9_Input = tf.concat([layer8_3,layer2_Input],axis=3)\n",
    "layer9_1 = l9_1.feedforward(layer9_Input)\n",
    "layer9_2 = l9_2.feedforward(layer9_1)\n",
    "layer9_3 = l9_3.feedforward(layer9_2)\n",
    "\n",
    "layer10_Input = layer9_3\n",
    "layer10_1 = l10_final.feedforward(layer10_Input)\n",
    "\n",
    "cost = tf.reduce_mean(tf.keras.losses.binary_crossentropy(train_labels,layer10_1))\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=init_lr).minimize(cost)\n",
    "\n",
    "# --- start session ---\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for iter in range(num_epoch):\n",
    "        \n",
    "        # train\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_batch = train_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "            current_label = train_labels[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "            sess_results = sess.run([cost,auto_train],feed_dict={x:current_batch,y:current_label})\n",
    "            print(' Iter: ', iter, \" Cost:  %.32f\"% sess_results[0],end='\\r')\n",
    "        print('\\n-----------------------')\n",
    "        train_images,train_labels = shuffle(train_images,train_labels)\n",
    "\n",
    "        if iter % 2 == 0:\n",
    "            test_example =   train_images[:2,:,:,:]\n",
    "            test_example_gt = train_labels[:2,:,:,:]\n",
    "            sess_results = sess.run([layer10],feed_dict={x:test_example})\n",
    "\n",
    "            sess_results = sess_results[0][0,:,:,:]\n",
    "            test_example = test_example[0,:,:,:]\n",
    "            test_example_gt = test_example_gt[0,:,:,:]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(test_example),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Original Image')\n",
    "            plt.savefig('train_change/'+str(iter)+\"a_Original_Image.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.savefig('train_change/'+str(iter)+\"b_Original_Mask.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(sess_results),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Generated Mask')\n",
    "            plt.savefig('train_change/'+str(iter)+\"c_Generated_Mask.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.multiply(np.squeeze(test_example),np.squeeze(test_example_gt)),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Ground Truth Overlay\")\n",
    "            plt.savefig('train_change/'+str(iter)+\"d_Original_Image_Overlay.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.axis('off')\n",
    "            plt.imshow(np.multiply(np.squeeze(test_example),np.squeeze(sess_results)),cmap='gray')\n",
    "            plt.title(\"Generated Overlay\")\n",
    "            plt.savefig('train_change/'+str(iter)+\"e_Generated_Image_Overlay.png\")\n",
    "\n",
    "            plt.close('all')\n",
    "\n",
    "    for data_index in range(0,len(train_images),batch_size):\n",
    "        current_batch = train_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "        sess_results = sess.run(layer10,feed_dict={x:current_batch})\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(np.squeeze(current_batch[0,:,:,:]),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(str(data_index)+\"a_Original Image\")\n",
    "        plt.savefig('gif/'+str(data_index)+\"a_Original_Image.png\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(np.squeeze(current_label[0,:,:,:]),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(str(data_index)+\"b_Original Mask\")\n",
    "        plt.savefig('gif/'+str(data_index)+\"b_Original_Mask.png\")\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(np.squeeze(sess_results[0,:,:,:]),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(str(data_index)+\"c_Generated Mask\")\n",
    "        plt.savefig('gif/'+str(data_index)+\"c_Generated_Mask.png\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(np.multiply(np.squeeze(current_batch[0,:,:,:]),np.squeeze(current_label[0,:,:,:])),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(str(data_index)+\"d_Original Image Overlay\")\n",
    "        plt.savefig('gif/'+str(data_index)+\"d_Original_Image_Overlay.png\")        \n",
    "        plt.savefig('gif/'+str(data_index)+\"d_Original_Image_Overlay.png\")\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(np.multiply(np.squeeze(current_batch[0,:,:,:]),np.squeeze(sess_results[0,:,:,:])),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(str(data_index)+\"e_Generated Image Overlay\")\n",
    "        plt.savefig('gif/'+str(data_index)+\"e_Generated_Image_Overlay.png\")\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "\n",
    "# -- end code --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
